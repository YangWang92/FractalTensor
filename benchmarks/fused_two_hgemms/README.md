<p align="center">
<img src="fractaltensor/figures/fused_two_gemms.png"  width=70%><br>
Fig. Compose back-to-back GEMMs using parallel operator nesting.
</p>

<p align="center">
<img src="fractaltensor/figures/etdg_for_two_gemms.png"  width=70%><br>
Fig. Extended task dependence graph representations for back-to-back GEMMs.
</p>

<p align="center">
<img src="fractaltensor/figures/access_maps.png" width=70%><br>
Fig. AccessMap annotation attached to the extended task dependence graph.
</p>

<p align="center">
<img src="fractaltensor/figures/gemm_translated_to_macro_kernel.png" width=70%><br>
Fig. Translate into heirarchical dataflow on the CUDA device.
</p>
