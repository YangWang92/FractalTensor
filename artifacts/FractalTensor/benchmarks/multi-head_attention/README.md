# Program Flash Attention with Parallel Operator Nesting

<p align="center">
<img src="fractaltensor/figures/flash_attention_with_parallel_operators.png" width=70%><br>
Fig. Program flash attention with parallel operator nesting.
</p>

<p align="center">
<img src="fractaltensor/figures/ETDG.png" width=80%><br>
Fig. Parse into nested ETDG representation.
</p>

<p align="center">
<img src="fractaltensor/figures/fused_etdg.png" width=80%><br>
Fig. Fused ETDG representation.
</p>

<p align="center">
<img src="fractaltensor/figures/map_to_cuda.png" width=80%><br>
Fig. Mapping to CUDA memory and compute hierarchy (the left part represents the imperative equivalent of Fused ETDG).
</p>
